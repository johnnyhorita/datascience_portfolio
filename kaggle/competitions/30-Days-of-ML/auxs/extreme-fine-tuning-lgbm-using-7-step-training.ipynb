{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01252,
     "end_time": "2021-02-28T02:59:50.289274",
     "exception": false,
     "start_time": "2021-02-28T02:59:50.276754",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Extreme Fine Tuning of LGBM using Incremental training\n",
    "\n",
    "\n",
    "In my efforts to push leaderboard i stumbled across a small trick to improve predictions in 4th to 5th decimal using same parameters and a single model, essentially it is a trick to improve prediction of your best parameter, squeezing more out of them!!. Trick is executed in following steps:\n",
    "\n",
    "* Find the best parameters for your LGBM, manually or using optimization methods of your choice.\n",
    "\n",
    "\n",
    "* train the model to the best RMSE you can get in one training round using high early stopping.\n",
    "\n",
    "\n",
    "* train the model for 1 or 2 rounds with reduced learning rate.\n",
    "\n",
    "\n",
    "* once the first few rounds are over, start reducing regularization params by a factor at each incremental training iteration, you will start observing improvements in 5th decimal place... which is enough to get 5th decimal improvement on your models leaderboard score.\n",
    "\n",
    "At the top of leaderboard this make a huge difference, i pushed my rank from `39` at **0.84202** to my best `6th place`(17th Feb 2021) with **0.84193**\n",
    "\n",
    "Lets check out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-28T02:59:50.315209Z",
     "iopub.status.busy": "2021-02-28T02:59:50.314355Z",
     "iopub.status.idle": "2021-02-28T02:59:52.032315Z",
     "shell.execute_reply": "2021-02-28T02:59:52.033087Z"
    },
    "papermill": {
     "duration": 1.732861,
     "end_time": "2021-02-28T02:59:52.033410",
     "exception": false,
     "start_time": "2021-02-28T02:59:50.300549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "import optuna\n",
    "from functools import partial\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-28T02:59:52.063291Z",
     "iopub.status.busy": "2021-02-28T02:59:52.061974Z",
     "iopub.status.idle": "2021-02-28T02:59:55.273289Z",
     "shell.execute_reply": "2021-02-28T02:59:55.272186Z"
    },
    "papermill": {
     "duration": 3.227388,
     "end_time": "2021-02-28T02:59:55.273505",
     "exception": false,
     "start_time": "2021-02-28T02:59:52.046117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/tabular-playground-series-feb-2021/train.csv')\n",
    "test = pd.read_csv('../input/tabular-playground-series-feb-2021/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-28T02:59:55.308589Z",
     "iopub.status.busy": "2021-02-28T02:59:55.307973Z",
     "iopub.status.idle": "2021-02-28T02:59:55.371227Z",
     "shell.execute_reply": "2021-02-28T02:59:55.370732Z"
    },
    "papermill": {
     "duration": 0.085788,
     "end_time": "2021-02-28T02:59:55.371414",
     "exception": false,
     "start_time": "2021-02-28T02:59:55.285626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = train.drop(['id', 'target'], axis=1)\n",
    "y_train = train.target\n",
    "X_test = test.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-28T02:59:55.400875Z",
     "iopub.status.busy": "2021-02-28T02:59:55.400325Z",
     "iopub.status.idle": "2021-02-28T02:59:55.403990Z",
     "shell.execute_reply": "2021-02-28T02:59:55.404454Z"
    },
    "papermill": {
     "duration": 0.020901,
     "end_time": "2021-02-28T02:59:55.404606",
     "exception": false,
     "start_time": "2021-02-28T02:59:55.383705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_cols = [feature for feature in train.columns if 'cat' in feature]\n",
    "\n",
    "def label_encoder(df):\n",
    "    for feature in cat_cols:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-28T02:59:55.476159Z",
     "iopub.status.busy": "2021-02-28T02:59:55.438230Z",
     "iopub.status.idle": "2021-02-28T02:59:56.320327Z",
     "shell.execute_reply": "2021-02-28T02:59:56.319819Z"
    },
    "papermill": {
     "duration": 0.9036,
     "end_time": "2021-02-28T02:59:56.320475",
     "exception": false,
     "start_time": "2021-02-28T02:59:55.416875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = label_encoder(X_train)\n",
    "X_test = label_encoder(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-28T02:59:56.349620Z",
     "iopub.status.busy": "2021-02-28T02:59:56.349071Z",
     "iopub.status.idle": "2021-02-28T02:59:56.353182Z",
     "shell.execute_reply": "2021-02-28T02:59:56.352605Z"
    },
    "papermill": {
     "duration": 0.020596,
     "end_time": "2021-02-28T02:59:56.353321",
     "exception": false,
     "start_time": "2021-02-28T02:59:56.332725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "split = KFold(n_splits=5, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-28T02:59:56.388164Z",
     "iopub.status.busy": "2021-02-28T02:59:56.387261Z",
     "iopub.status.idle": "2021-02-28T02:59:56.390056Z",
     "shell.execute_reply": "2021-02-28T02:59:56.389626Z"
    },
    "papermill": {
     "duration": 0.024314,
     "end_time": "2021-02-28T02:59:56.390184",
     "exception": false,
     "start_time": "2021-02-28T02:59:56.365870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial, X, y, name='xgb'):\n",
    "        \n",
    "    params = {'max_depth':trial.suggest_int('max_depth', 5, 50),\n",
    "              'n_estimators':200000,\n",
    "              #'boosting':trial.suggest_categorical('boosting', ['gbdt', 'dart', 'goss']),\n",
    "              'subsample': trial.suggest_uniform('subsample', 0.2, 1.0),\n",
    "              'colsample_bytree':trial.suggest_uniform('colsample_bytree', 0.2, 1.0),\n",
    "              'learning_rate':trial.suggest_uniform('learning_rate', 0.007, 0.02),\n",
    "              'reg_lambda':trial.suggest_uniform('reg_lambda', 0.01, 50),\n",
    "              'reg_alpha':trial.suggest_uniform('reg_alpha', 0.01, 50),\n",
    "              'min_child_samples':trial.suggest_int('min_child_samples', 5, 100),\n",
    "              'num_leaves':trial.suggest_int('num_leaves', 10, 200),\n",
    "              'n_jobs' : -1,\n",
    "              'metric':'rmse',\n",
    "              'max_bin':trial.suggest_int('max_bin', 300, 1000),\n",
    "              'cat_smooth':trial.suggest_int('cat_smooth', 5, 100),\n",
    "              'cat_l2':trial.suggest_loguniform('cat_l2', 1e-3, 100)}\n",
    "\n",
    "    model = LGBMRegressor(**params)\n",
    "                  \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    \n",
    "\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)],\n",
    "              eval_metric=['rmse'],\n",
    "              early_stopping_rounds=250, \n",
    "              categorical_feature=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "              #callbacks=[optuna.integration.LightGBMPruningCallback(trial, metric='rmse')],\n",
    "              verbose=0)\n",
    "\n",
    "    train_score = np.round(np.sqrt(mean_squared_error(y_train, model.predict(X_train))), 5)\n",
    "    test_score = np.round(np.sqrt(mean_squared_error(y_val, model.predict(X_val))), 5)\n",
    "                  \n",
    "    print(f'TRAIN RMSE : {train_score} || TEST RMSE : {test_score}')\n",
    "                  \n",
    "    return test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-28T02:59:56.420183Z",
     "iopub.status.busy": "2021-02-28T02:59:56.419594Z",
     "iopub.status.idle": "2021-02-28T02:59:56.423127Z",
     "shell.execute_reply": "2021-02-28T02:59:56.423571Z"
    },
    "papermill": {
     "duration": 0.020113,
     "end_time": "2021-02-28T02:59:56.423714",
     "exception": false,
     "start_time": "2021-02-28T02:59:56.403601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-28 02:59:56,418]\u001b[0m A new study created in memory with name: no-name-f225b33e-77e3-4f3c-a879-eab427aa42c0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "optimize = partial(objective, X=X_train, y=y_train)\n",
    "\n",
    "study_lgbm = optuna.create_study(direction='minimize')\n",
    "#study_lgbm.optimize(optimize, n_trials=300)\n",
    "\n",
    "# i have commented out the trials so as to cut short the notebook execution time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-28T02:59:56.451473Z",
     "iopub.status.busy": "2021-02-28T02:59:56.450937Z",
     "iopub.status.idle": "2021-02-28T02:59:56.455135Z",
     "shell.execute_reply": "2021-02-28T02:59:56.455593Z"
    },
    "papermill": {
     "duration": 0.019446,
     "end_time": "2021-02-28T02:59:56.455733",
     "exception": false,
     "start_time": "2021-02-28T02:59:56.436287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#From the above optuna trials the best parameters i could find were the following ones!\n",
    "\n",
    "lgbm_params = {'max_depth': 16, \n",
    "                'subsample': 0.8032697250789377, \n",
    "                'colsample_bytree': 0.21067140508531404, \n",
    "                'learning_rate': 0.009867383057779643,\n",
    "                'reg_lambda': 10.987474846877767, \n",
    "                'reg_alpha': 17.335285595031994, \n",
    "                'min_child_samples': 31, \n",
    "                'num_leaves': 66, \n",
    "                'max_bin': 522, \n",
    "                'cat_smooth': 81, \n",
    "                'cat_l2': 0.029690334194270022, \n",
    "                'metric': 'rmse', \n",
    "                'n_jobs': -1, \n",
    "                'n_estimators': 20000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-28T02:59:56.484001Z",
     "iopub.status.busy": "2021-02-28T02:59:56.483450Z",
     "iopub.status.idle": "2021-02-28T04:27:02.790735Z",
     "shell.execute_reply": "2021-02-28T04:27:02.791742Z"
    },
    "papermill": {
     "duration": 5226.323589,
     "end_time": "2021-02-28T04:27:02.791998",
     "exception": false,
     "start_time": "2021-02-28T02:59:56.468409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Base model is 0.8417931738282095\n",
      "RMSE for Incremental trial 1 model is 0.8417915156558853\n",
      "RMSE for Incremental trial 2 model is 0.8417684019997734\n",
      "RMSE for Incremental trial 3 model is 0.8417660944976237\n",
      "RMSE for Incremental trial 4 model is 0.8417479412660887\n",
      "RMSE for Incremental trial 5 model is 0.8417466948697506\n",
      "RMSE for Incremental trial 6 model is 0.8417400362504809\n",
      "RMSE for Incremental trial 7 model is 0.8417363457753021\n",
      "\n",
      "\n",
      "Improvement of : 5.682805290740944e-05\n",
      "----------------------------------------------------------------------------------------------------\n",
      "RMSE for Base model is 0.8414227087407661\n",
      "RMSE for Incremental trial 1 model is 0.8414146015100101\n",
      "RMSE for Incremental trial 2 model is 0.8414112084375642\n",
      "RMSE for Incremental trial 3 model is 0.8414093495351639\n",
      "RMSE for Incremental trial 4 model is 0.8414090703491379\n",
      "RMSE for Incremental trial 5 model is 0.8414084284185339\n",
      "RMSE for Incremental trial 6 model is 0.8414080942426032\n",
      "RMSE for Incremental trial 7 model is 0.8414077246125012\n",
      "\n",
      "\n",
      "Improvement of : 1.4984128264838859e-05\n",
      "----------------------------------------------------------------------------------------------------\n",
      "RMSE for Base model is 0.8429314566746714\n",
      "RMSE for Incremental trial 1 model is 0.8428819480239788\n",
      "RMSE for Incremental trial 2 model is 0.8428685997480563\n",
      "RMSE for Incremental trial 3 model is 0.8428631753500512\n",
      "RMSE for Incremental trial 4 model is 0.8428593986647801\n",
      "RMSE for Incremental trial 5 model is 0.8428557465303208\n",
      "RMSE for Incremental trial 6 model is 0.8428550544659699\n",
      "RMSE for Incremental trial 7 model is 0.8428528899037318\n",
      "\n",
      "\n",
      "Improvement of : 7.856677093964759e-05\n",
      "----------------------------------------------------------------------------------------------------\n",
      "RMSE for Base model is 0.8429924294348647\n",
      "RMSE for Incremental trial 1 model is 0.8429695875279826\n",
      "RMSE for Incremental trial 2 model is 0.8429537650790004\n",
      "RMSE for Incremental trial 3 model is 0.8429533725760774\n",
      "RMSE for Incremental trial 4 model is 0.8429534052718782\n",
      "RMSE for Incremental trial 5 model is 0.8429532870510614\n",
      "RMSE for Incremental trial 6 model is 0.8429530840452732\n",
      "RMSE for Incremental trial 7 model is 0.8429529679033158\n",
      "\n",
      "\n",
      "Improvement of : 3.94615315489899e-05\n",
      "----------------------------------------------------------------------------------------------------\n",
      "RMSE for Base model is 0.8403871758750866\n",
      "RMSE for Incremental trial 1 model is 0.8403814937989306\n",
      "RMSE for Incremental trial 2 model is 0.8403751130622852\n",
      "RMSE for Incremental trial 3 model is 0.8403732324317731\n",
      "RMSE for Incremental trial 4 model is 0.8403734400619804\n",
      "RMSE for Incremental trial 5 model is 0.8403734515933802\n",
      "RMSE for Incremental trial 6 model is 0.8403729528575061\n",
      "RMSE for Incremental trial 7 model is 0.8403722878866788\n",
      "\n",
      "\n",
      "Improvement of : 1.4887988407763508e-05\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "preds_list_base = []\n",
    "preds_list_final_iteration = []\n",
    "preds_list_all = []\n",
    "\n",
    "for train_idx, val_idx in split.split(X_train):\n",
    "            X_tr = X_train.iloc[train_idx]\n",
    "            X_val = X_train.iloc[val_idx]\n",
    "            y_tr = y_train.iloc[train_idx]\n",
    "            y_val = y_train.iloc[val_idx]\n",
    "            \n",
    "            Model = LGBMRegressor(**lgbm_params).fit(X_tr, y_tr, eval_set=[(X_val, y_val)],\n",
    "                          eval_metric=['rmse'],\n",
    "                          early_stopping_rounds=250, \n",
    "                          categorical_feature=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                          #callbacks=[optuna.integration.LightGBMPruningCallback(trial, metric='rmse')],\n",
    "                          verbose=0)\n",
    "            \n",
    "            preds_list_base.append(Model.predict(X_test))\n",
    "            preds_list_all.append(Model.predict(X_test))\n",
    "            print(f'RMSE for Base model is {np.sqrt(mean_squared_error(y_val, Model.predict(X_val)))}')\n",
    "            first_rmse = np.sqrt(mean_squared_error(y_val, Model.predict(X_val)))\n",
    "            params = lgbm_params.copy()\n",
    "            \n",
    "            for i in range(1, 8):\n",
    "                if i >2:    \n",
    "                    \n",
    "                    # reducing regularizing params if \n",
    "                    \n",
    "                    params['reg_lambda'] *= 0.9\n",
    "                    params['reg_alpha'] *= 0.9\n",
    "                    params['num_leaves'] += 40\n",
    "                    \n",
    "                params['learning_rate'] = 0.003\n",
    "                Model = LGBMRegressor(**params).fit(X_tr, y_tr, eval_set=[(X_val, y_val)],\n",
    "                          eval_metric=['rmse'],\n",
    "                          early_stopping_rounds=200, \n",
    "                          categorical_feature=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                          #callbacks=[optuna.integration.LightGBMPruningCallback(trial, metric='rmse')],\n",
    "                          verbose=0,\n",
    "                          init_model=Model)\n",
    "                \n",
    "                preds_list_all.append(Model.predict(X_test))\n",
    "                print(f'RMSE for Incremental trial {i} model is {np.sqrt(mean_squared_error(y_val, Model.predict(X_val)))}')\n",
    "            last_rmse = np.sqrt(mean_squared_error(y_val, Model.predict(X_val)))\n",
    "            print('',end='\\n\\n')\n",
    "            print(f'Improvement of : {first_rmse - last_rmse}')\n",
    "            print('-' * 100)\n",
    "            preds_list_final_iteration.append(Model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022948,
     "end_time": "2021-02-28T04:27:02.838620",
     "exception": false,
     "start_time": "2021-02-28T04:27:02.815672",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Great!! we can see that we have observed some further improvement in all the folds. Lets point out few findings:\n",
    "\n",
    "* The first few iterations are just using very low learning_rate.. after the 2nd iteration we can see that there are iterations with very good improvement, observed by reducing regularization.\n",
    "\n",
    "\n",
    "* There are also iterations where loss increased at later iterations slightly compared to previous iteration, showing that we have reached the limit in few iterations before the max iteration.\n",
    "\n",
    "\n",
    "* If you try setting verbose=1, you will observe that these improvements are observed only in first few trees created... after that loss starts to increase, LGBM keeps the best model. But reducing regularization does improve loss for first few trees!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024336,
     "end_time": "2021-02-28T04:27:02.886212",
     "exception": false,
     "start_time": "2021-02-28T04:27:02.861876",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I have 3 different sets of predictions, one for only the base model and one for all the predictions done and last one for only final iteration.\n",
    "\n",
    "* `y_preds_base` : **0.84196 - 0.84199** (keeps jumping between these)\n",
    "\n",
    "\n",
    "* `y_preds_all` : **0.84195 - 0.84196**\n",
    "\n",
    "\n",
    "* `y_preds_final_iteration` : **0.84193**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-28T04:27:02.944652Z",
     "iopub.status.busy": "2021-02-28T04:27:02.943984Z",
     "iopub.status.idle": "2021-02-28T04:27:02.954283Z",
     "shell.execute_reply": "2021-02-28T04:27:02.953835Z"
    },
    "papermill": {
     "duration": 0.038323,
     "end_time": "2021-02-28T04:27:02.954418",
     "exception": false,
     "start_time": "2021-02-28T04:27:02.916095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.61265617, 7.78756299, 7.60367127, ..., 7.53725979, 7.50144961,\n",
       "       7.27430572])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_base = np.array(preds_list_base).mean(axis=0)\n",
    "y_preds_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-28T04:27:03.007930Z",
     "iopub.status.busy": "2021-02-28T04:27:03.007370Z",
     "iopub.status.idle": "2021-02-28T04:27:03.049277Z",
     "shell.execute_reply": "2021-02-28T04:27:03.048804Z"
    },
    "papermill": {
     "duration": 0.070392,
     "end_time": "2021-02-28T04:27:03.049416",
     "exception": false,
     "start_time": "2021-02-28T04:27:02.979024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.61422684, 7.78663938, 7.60104474, ..., 7.5370382 , 7.50130437,\n",
       "       7.27273157])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_all = np.array(preds_list_all).mean(axis=0)\n",
    "y_preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-28T04:27:03.101839Z",
     "iopub.status.busy": "2021-02-28T04:27:03.101288Z",
     "iopub.status.idle": "2021-02-28T04:27:03.109659Z",
     "shell.execute_reply": "2021-02-28T04:27:03.109209Z"
    },
    "papermill": {
     "duration": 0.036369,
     "end_time": "2021-02-28T04:27:03.109797",
     "exception": false,
     "start_time": "2021-02-28T04:27:03.073428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.61448924, 7.78590933, 7.5991315 , ..., 7.53653038, 7.50137286,\n",
       "       7.27124171])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_final_iteration = np.array(preds_list_final_iteration).mean(axis=0)\n",
    "y_preds_final_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-28T04:27:03.165503Z",
     "iopub.status.busy": "2021-02-28T04:27:03.164854Z",
     "iopub.status.idle": "2021-02-28T04:27:03.166903Z",
     "shell.execute_reply": "2021-02-28T04:27:03.167340Z"
    },
    "papermill": {
     "duration": 0.032685,
     "end_time": "2021-02-28T04:27:03.167498",
     "exception": false,
     "start_time": "2021-02-28T04:27:03.134813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id':test.id,\n",
    "              'target':y_preds_final_iteration})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-28T04:27:03.219256Z",
     "iopub.status.busy": "2021-02-28T04:27:03.218676Z",
     "iopub.status.idle": "2021-02-28T04:27:03.674578Z",
     "shell.execute_reply": "2021-02-28T04:27:03.675026Z"
    },
    "papermill": {
     "duration": 0.483037,
     "end_time": "2021-02-28T04:27:03.675201",
     "exception": false,
     "start_time": "2021-02-28T04:27:03.192164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-28T04:27:03.728093Z",
     "iopub.status.busy": "2021-02-28T04:27:03.727476Z",
     "iopub.status.idle": "2021-02-28T04:27:03.789076Z",
     "shell.execute_reply": "2021-02-28T04:27:03.789499Z"
    },
    "papermill": {
     "duration": 0.0902,
     "end_time": "2021-02-28T04:27:03.789665",
     "exception": false,
     "start_time": "2021-02-28T04:27:03.699465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7.614489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>7.785909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>7.599132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>7.526873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>7.258177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>499987</td>\n",
       "      <td>7.492011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>499990</td>\n",
       "      <td>7.247003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>499991</td>\n",
       "      <td>7.536530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>499994</td>\n",
       "      <td>7.501373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>499995</td>\n",
       "      <td>7.271242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    target\n",
       "0            0  7.614489\n",
       "1            5  7.785909\n",
       "2           15  7.599132\n",
       "3           16  7.526873\n",
       "4           17  7.258177\n",
       "...        ...       ...\n",
       "199995  499987  7.492011\n",
       "199996  499990  7.247003\n",
       "199997  499991  7.536530\n",
       "199998  499994  7.501373\n",
       "199999  499995  7.271242\n",
       "\n",
       "[200000 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024884,
     "end_time": "2021-02-28T04:27:03.839694",
     "exception": false,
     "start_time": "2021-02-28T04:27:03.814810",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Finding the right regularization reducing factors using optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024665,
     "end_time": "2021-02-28T04:27:03.889214",
     "exception": false,
     "start_time": "2021-02-28T04:27:03.864549",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "you may even try reducing or increasing few params and find the best mix of factors using optuna, it may even be possible to improve results more than achieved above, an example of the technique is shown below... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-28T04:27:03.942960Z",
     "iopub.status.busy": "2021-02-28T04:27:03.942364Z",
     "iopub.status.idle": "2021-02-28T04:27:52.098692Z",
     "shell.execute_reply": "2021-02-28T04:27:52.098056Z"
    },
    "papermill": {
     "duration": 48.184184,
     "end_time": "2021-02-28T04:27:52.098829",
     "exception": false,
     "start_time": "2021-02-28T04:27:03.914645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creating a pre trained model to use in objective.\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "lgbm = LGBMRegressor(**lgbm_params).fit(X_tr, y_tr, eval_set=[(X_val, y_val)],\n",
    "                          eval_metric=['rmse'],\n",
    "                          early_stopping_rounds=250, \n",
    "                          categorical_feature=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                          verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-28T04:27:52.159445Z",
     "iopub.status.busy": "2021-02-28T04:27:52.158490Z",
     "iopub.status.idle": "2021-02-28T04:27:52.161450Z",
     "shell.execute_reply": "2021-02-28T04:27:52.160961Z"
    },
    "papermill": {
     "duration": 0.037502,
     "end_time": "2021-02-28T04:27:52.161591",
     "exception": false,
     "start_time": "2021-02-28T04:27:52.124089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial, model, X, y, iterations=5):\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    f1 = trial.suggest_uniform('f1', 0.1, 1.0)\n",
    "    f2 = trial.suggest_uniform('f2', 0.1, 3)\n",
    "    f3 = trial.suggest_int('f3', 20, 100)\n",
    "    f4 = trial.suggest_int('f4', 20, 50)\n",
    "    f5 = trial.suggest_int('f5', 1, 5)\n",
    "    lr_factor = trial.suggest_uniform('lr_factor', 0.1, 0.7)\n",
    "    \n",
    "    \n",
    "    params = lgbm_params.copy()\n",
    "    print(f'RMSE for base model is {np.sqrt(mean_squared_error(y_val, Model.predict(X_val)))}')\n",
    "\n",
    "    for i in range(1, iterations):\n",
    "        if i > 2:\n",
    "            params['reg_lambda'] *=  f1\n",
    "            params['reg_alpha'] += f2\n",
    "            params['num_leaves'] += f3\n",
    "            params['min_child_samples'] -= f4\n",
    "            params['cat_smooth'] -= f5\n",
    "            params['learning_rate'] *= lr_factor\n",
    "            #params['max_depth'] += f5\n",
    "\n",
    "       \n",
    "        params['learning_rate'] = params['learning_rate'] if params['learning_rate'] > 0.0009 else 0.0009\n",
    "        # need to stop learning rate to reduce to a very insignificant value, hence we use this threshold\n",
    "        \n",
    "        Model = model(**params).fit(X_train, y_train, eval_set=[(X_val, y_val)],\n",
    "                          eval_metric=['rmse'],\n",
    "                          early_stopping_rounds=200, \n",
    "                          categorical_feature=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                          verbose=1000,\n",
    "                          init_model=Model if i > 1 else lgbm)# we will use pre trained model for first iteration\n",
    "     \n",
    "        print(f'RMSE for {i}th model is {np.sqrt(mean_squared_error(y_val, Model.predict(X_val)))}')\n",
    "           \n",
    "              \n",
    "    RMSE = mean_squared_error(y_val, Model.predict(X_val), squared=False)\n",
    "    return RMSE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-28T04:27:52.217066Z",
     "iopub.status.busy": "2021-02-28T04:27:52.216127Z",
     "iopub.status.idle": "2021-02-28T04:27:52.221854Z",
     "shell.execute_reply": "2021-02-28T04:27:52.221435Z"
    },
    "papermill": {
     "duration": 0.035319,
     "end_time": "2021-02-28T04:27:52.221990",
     "exception": false,
     "start_time": "2021-02-28T04:27:52.186671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-28 04:27:52,214]\u001b[0m A new study created in memory with name: no-name-d2dbf237-f597-4230-927b-7b2f9aa5d1e5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "optimize = partial(objective, X=X_train, y=y_train, model=LGBMRegressor)\n",
    "#study.optimize(optimize, n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025396,
     "end_time": "2021-02-28T04:27:52.273108",
     "exception": false,
     "start_time": "2021-02-28T04:27:52.247712",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally, i am still working on and experimenting why this actually works, few things i have found are:\n",
    "\n",
    "* using only iterations with some reduction in learning rate will not give you results as good as reducing regularization at each iteration, loss improvement plateaus pretty qucikly and starts worsening in after few iterations, reducing regularizatioj too forces some more loss improvement and helps get more iterations in.\n",
    "\n",
    "\n",
    "* Reducing regularization slowly forecefully improves loss at every next iteration until a bottleneck is reached, where this trick just does not work anymore, The reason for this can be maybe for the first few trees added at a new iteration with reduced regularization, the minute changes they bring to decision boundary even though overfit inducing should help generalize for just first few trees, after that overfitting starts to increase and loss shots up during each iteration, its great that lgbm iternally stores the best loss at each training!!\n",
    "\n",
    "**Although a small trick this work has been a hardwork of few days, so if you like the work and find it useful, show your support by upvoting!!** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.02561,
     "end_time": "2021-02-28T04:27:52.324525",
     "exception": false,
     "start_time": "2021-02-28T04:27:52.298915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5287.621918,
   "end_time": "2021-02-28T04:27:53.060026",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-28T02:59:45.438108",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
