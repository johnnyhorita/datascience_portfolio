{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import helpful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T13:10:15.703325Z",
     "start_time": "2021-08-26T13:10:07.762753Z"
    },
    "execution": {
     "iopub.execute_input": "2021-08-25T20:05:40.818569Z",
     "iopub.status.busy": "2021-08-25T20:05:40.817800Z",
     "iopub.status.idle": "2021-08-25T20:05:45.598187Z",
     "shell.execute_reply": "2021-08-25T20:05:45.597276Z",
     "shell.execute_reply.started": "2021-08-25T20:05:40.818450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set up complete\n"
     ]
    }
   ],
   "source": [
    "# Familiar imports\n",
    "\n",
    "#basic tools \n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#graph, plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For ordinal encoding categorical variables, splitting data\n",
    "import sklearn as sk\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, roc_curve\n",
    "\n",
    "# For training LGBM\n",
    "from lightgbm import LGBMRegressor\n",
    "from tqdm import tqdm\n",
    "import xgboost as xgb\n",
    "\n",
    "#tuning hyperparameters\n",
    "from skopt  import BayesSearchCV \n",
    "\n",
    "import optuna\n",
    "from functools import partial\n",
    "from termcolor import colored\n",
    "\n",
    "import shap\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "print(\"set up complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T13:10:15.712294Z",
     "start_time": "2021-08-26T13:10:15.704321Z"
    },
    "execution": {
     "iopub.execute_input": "2021-08-25T20:05:50.218233Z",
     "iopub.status.busy": "2021-08-25T20:05:50.217678Z",
     "iopub.status.idle": "2021-08-25T20:05:50.227299Z",
     "shell.execute_reply": "2021-08-25T20:05:50.225673Z",
     "shell.execute_reply.started": "2021-08-25T20:05:50.218181Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SciKit Learn: 0.23.2\n",
      "Pandas: 1.3.1\n",
      "Numpy: 1.20.3\n",
      "Seaborn: 0.11.2\n"
     ]
    }
   ],
   "source": [
    "#Python libraries and their versions used for this problem\n",
    "print('SciKit Learn:',sk.__version__)\n",
    "print('Pandas:',pd.__version__)\n",
    "print('Numpy:',np.__version__)\n",
    "print('Seaborn:',sns.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T13:10:15.725296Z",
     "start_time": "2021-08-26T13:10:15.714293Z"
    },
    "execution": {
     "iopub.execute_input": "2021-08-25T20:05:59.019167Z",
     "iopub.status.busy": "2021-08-25T20:05:59.018746Z",
     "iopub.status.idle": "2021-08-25T20:05:59.034958Z",
     "shell.execute_reply": "2021-08-25T20:05:59.033789Z",
     "shell.execute_reply.started": "2021-08-25T20:05:59.019129Z"
    }
   },
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/make-working-with-large-dataframes-easier-at-least-for-your-memory-6f52b5f4b5c4\n",
    "    \n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int8','int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T13:10:17.669740Z",
     "start_time": "2021-08-26T13:10:15.728297Z"
    },
    "execution": {
     "iopub.execute_input": "2021-08-25T20:06:06.687324Z",
     "iopub.status.busy": "2021-08-25T20:06:06.686725Z",
     "iopub.status.idle": "2021-08-25T20:06:12.040236Z",
     "shell.execute_reply": "2021-08-25T20:06:12.039224Z",
     "shell.execute_reply.started": "2021-08-25T20:06:06.687286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 33.76 Mb (43.3% reduction)\n",
      "Mem. usage decreased to 22.13 Mb (42.0% reduction)\n",
      "\n",
      "Shape of train set:  (300000, 25)\n",
      "Shape of test set:  (200000, 24)\n",
      "\n",
      "load complete\n",
      "Wall time: 1.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#local\n",
    "train = reduce_mem_usage(pd.read_csv(\"./dataset/train.csv\",encoding='utf-8', index_col=0, low_memory=False))\n",
    "test = reduce_mem_usage(pd.read_csv(\"./dataset/test.csv\",encoding='utf-8', index_col=0, low_memory=False))\n",
    "\n",
    "#Internet\n",
    "#train = reduce_mem_usage(pd.read_csv(\"../input/30-days-of-ml/train.csv\",encoding='utf-8', index_col=0, low_memory=False))\n",
    "#test = reduce_mem_usage(pd.read_csv(\"../input/30-days-of-ml/test.csv\",encoding='utf-8', index_col=0, low_memory=False))\n",
    "\n",
    "#Sem redução de espaço\n",
    "#train = pd.read_csv(\"../input/30-days-of-ml/train.csv\",encoding='utf-8', index_col=0, low_memory=False)\n",
    "#test = pd.read_csv(\"../input/30-days-of-ml/test.csv\",encoding='utf-8', index_col=0, low_memory=False)\n",
    "\n",
    "print(\"\\nShape of train set: \",train.shape)\n",
    "print(\"Shape of test set: \",test.shape)\n",
    "\n",
    "print(\"\\nload complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T13:10:17.703462Z",
     "start_time": "2021-08-26T13:10:17.670732Z"
    },
    "execution": {
     "iopub.execute_input": "2021-08-25T20:06:17.058696Z",
     "iopub.status.busy": "2021-08-25T20:06:17.058061Z",
     "iopub.status.idle": "2021-08-25T20:06:17.097560Z",
     "shell.execute_reply": "2021-08-25T20:06:17.096344Z",
     "shell.execute_reply.started": "2021-08-25T20:06:17.058655Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>...</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400391</td>\n",
       "      <td>0.160278</td>\n",
       "      <td>0.311035</td>\n",
       "      <td>0.389404</td>\n",
       "      <td>0.267578</td>\n",
       "      <td>0.237305</td>\n",
       "      <td>0.377930</td>\n",
       "      <td>0.322510</td>\n",
       "      <td>0.869629</td>\n",
       "      <td>8.117188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>O</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533203</td>\n",
       "      <td>0.559082</td>\n",
       "      <td>0.516113</td>\n",
       "      <td>0.594727</td>\n",
       "      <td>0.341553</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.261963</td>\n",
       "      <td>0.465088</td>\n",
       "      <td>8.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>0.650391</td>\n",
       "      <td>0.375244</td>\n",
       "      <td>0.902344</td>\n",
       "      <td>0.555176</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.749023</td>\n",
       "      <td>0.620117</td>\n",
       "      <td>0.541504</td>\n",
       "      <td>0.763672</td>\n",
       "      <td>8.367188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9  ...     cont5     cont6  \\\n",
       "id                                                    ...                       \n",
       "1     B    B    B    C    B    B    A    E    C    N  ...  0.400391  0.160278   \n",
       "2     B    B    A    A    B    D    A    F    A    O  ...  0.533203  0.559082   \n",
       "3     A    A    A    C    B    D    A    D    A    F  ...  0.650391  0.375244   \n",
       "\n",
       "       cont7     cont8     cont9    cont10    cont11    cont12    cont13  \\\n",
       "id                                                                         \n",
       "1   0.311035  0.389404  0.267578  0.237305  0.377930  0.322510  0.869629   \n",
       "2   0.516113  0.594727  0.341553  0.906250  0.921875  0.261963  0.465088   \n",
       "3   0.902344  0.555176  0.843750  0.749023  0.620117  0.541504  0.763672   \n",
       "\n",
       "      target  \n",
       "id            \n",
       "1   8.117188  \n",
       "2   8.484375  \n",
       "3   8.367188  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview data\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T13:10:18.064965Z",
     "start_time": "2021-08-26T13:10:17.704468Z"
    },
    "execution": {
     "iopub.execute_input": "2021-08-25T20:06:19.051191Z",
     "iopub.status.busy": "2021-08-25T20:06:19.050779Z",
     "iopub.status.idle": "2021-08-25T20:06:19.946002Z",
     "shell.execute_reply": "2021-08-25T20:06:19.944843Z",
     "shell.execute_reply.started": "2021-08-25T20:06:19.051154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 300000 entries, 1 to 499999\n",
      "Data columns (total 25 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   cat0    300000 non-null  object \n",
      " 1   cat1    300000 non-null  object \n",
      " 2   cat2    300000 non-null  object \n",
      " 3   cat3    300000 non-null  object \n",
      " 4   cat4    300000 non-null  object \n",
      " 5   cat5    300000 non-null  object \n",
      " 6   cat6    300000 non-null  object \n",
      " 7   cat7    300000 non-null  object \n",
      " 8   cat8    300000 non-null  object \n",
      " 9   cat9    300000 non-null  object \n",
      " 10  cont0   300000 non-null  float16\n",
      " 11  cont1   300000 non-null  float16\n",
      " 12  cont2   300000 non-null  float16\n",
      " 13  cont3   300000 non-null  float16\n",
      " 14  cont4   300000 non-null  float16\n",
      " 15  cont5   300000 non-null  float16\n",
      " 16  cont6   300000 non-null  float16\n",
      " 17  cont7   300000 non-null  float16\n",
      " 18  cont8   300000 non-null  float16\n",
      " 19  cont9   300000 non-null  float16\n",
      " 20  cont10  300000 non-null  float16\n",
      " 21  cont11  300000 non-null  float16\n",
      " 22  cont12  300000 non-null  float16\n",
      " 23  cont13  300000 non-null  float16\n",
      " 24  target  300000 non-null  float16\n",
      "dtypes: float16(15), object(10)\n",
      "memory usage: 176.8 MB\n"
     ]
    }
   ],
   "source": [
    "train.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T13:10:18.178156Z",
     "start_time": "2021-08-26T13:10:18.065966Z"
    },
    "execution": {
     "iopub.execute_input": "2021-08-25T20:06:22.529336Z",
     "iopub.status.busy": "2021-08-25T20:06:22.528771Z",
     "iopub.status.idle": "2021-08-25T20:06:22.857059Z",
     "shell.execute_reply": "2021-08-25T20:06:22.856146Z",
     "shell.execute_reply.started": "2021-08-25T20:06:22.529298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info about train data: \n",
      "Number of rows: \u001b[32m300000\u001b[0m\n",
      "Number of columns: \u001b[32m25\u001b[0m\n",
      "Number of missing values: \u001b[32m0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print('Info about train data: ')\n",
    "print('Number of rows:',colored(train.shape[0],'green'))\n",
    "print('Number of columns:',colored(train.shape[1],'green'))\n",
    "print('Number of missing values:',colored(sum(train.isna().sum()),'green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T13:10:18.220142Z",
     "start_time": "2021-08-26T13:10:18.180107Z"
    },
    "execution": {
     "iopub.execute_input": "2021-08-25T20:06:24.728096Z",
     "iopub.status.busy": "2021-08-25T20:06:24.727484Z",
     "iopub.status.idle": "2021-08-25T20:06:24.773694Z",
     "shell.execute_reply": "2021-08-25T20:06:24.772481Z",
     "shell.execute_reply.started": "2021-08-25T20:06:24.728054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of numerical columns is: \u001b[32m14\u001b[0m \n",
      "Number of categorical columsn is: \u001b[32m10\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "num_col = list(train.select_dtypes(include='float16').columns)\n",
    "cat_cols = list(train.select_dtypes(include='object').columns)\n",
    "num_col.remove('target')\n",
    "print('Number of numerical columns is:',colored(len(num_col),'green'),\n",
    "      '\\nNumber of categorical columsn is:',colored(len(cat_cols),'green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T13:10:18.252111Z",
     "start_time": "2021-08-26T13:10:18.221135Z"
    },
    "execution": {
     "iopub.execute_input": "2021-08-25T20:06:26.587005Z",
     "iopub.status.busy": "2021-08-25T20:06:26.586653Z",
     "iopub.status.idle": "2021-08-25T20:06:26.642340Z",
     "shell.execute_reply": "2021-08-25T20:06:26.641265Z",
     "shell.execute_reply.started": "2021-08-25T20:06:26.586973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target column basic statistics:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    300000.000000\n",
       "mean               NaN\n",
       "std           0.000000\n",
       "min           0.140381\n",
       "25%           7.742188\n",
       "50%           8.187500\n",
       "75%           8.726562\n",
       "max          10.414062\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('target column basic statistics:')\n",
    "target=train['target'].copy()\n",
    "target.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T13:10:18.297142Z",
     "start_time": "2021-08-26T13:10:18.253108Z"
    },
    "execution": {
     "iopub.execute_input": "2021-08-25T20:06:34.918879Z",
     "iopub.status.busy": "2021-08-25T20:06:34.918496Z",
     "iopub.status.idle": "2021-08-25T20:06:34.964911Z",
     "shell.execute_reply": "2021-08-25T20:06:34.963949Z",
     "shell.execute_reply.started": "2021-08-25T20:06:34.918845Z"
    }
   },
   "outputs": [],
   "source": [
    "# Separate target from features\n",
    "y_train = train['target'].copy()\n",
    "X_train = train.drop(['target'], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T13:10:18.303113Z",
     "start_time": "2021-08-26T13:10:18.298107Z"
    },
    "execution": {
     "iopub.execute_input": "2021-08-25T20:06:37.722988Z",
     "iopub.status.busy": "2021-08-25T20:06:37.722609Z",
     "iopub.status.idle": "2021-08-25T20:06:37.729265Z",
     "shell.execute_reply": "2021-08-25T20:06:37.728007Z",
     "shell.execute_reply.started": "2021-08-25T20:06:37.722948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mTrue\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Assuring that test data and whether or not it has the same columns as the train\n",
    "if list(test.columns) == list(X_train.columns):\n",
    "    print(colored('True', 'green'))  \n",
    "else:\n",
    "    print(colored('False', 'red'))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T13:10:18.487165Z",
     "start_time": "2021-08-26T13:10:18.304110Z"
    },
    "execution": {
     "iopub.execute_input": "2021-08-25T20:06:41.419948Z",
     "iopub.status.busy": "2021-08-25T20:06:41.419495Z",
     "iopub.status.idle": "2021-08-25T20:06:41.947593Z",
     "shell.execute_reply": "2021-08-25T20:06:41.946382Z",
     "shell.execute_reply.started": "2021-08-25T20:06:41.419900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train null values: \u001b[32m0\u001b[0m\n",
      "Test null values: \u001b[32m0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Checking if there are missing values in the datasets\n",
    "#Train\n",
    "print(f'Train null values:',colored(X_train.isna().sum().sum(), 'green'))\n",
    "\n",
    "#Test\n",
    "print(f'Test null values:',colored(test.isna().sum().sum(), 'green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T13:10:18.516165Z",
     "start_time": "2021-08-26T13:10:18.488191Z"
    },
    "execution": {
     "iopub.execute_input": "2021-08-25T20:06:44.713254Z",
     "iopub.status.busy": "2021-08-25T20:06:44.712833Z",
     "iopub.status.idle": "2021-08-25T20:06:44.751807Z",
     "shell.execute_reply": "2021-08-25T20:06:44.750405Z",
     "shell.execute_reply.started": "2021-08-25T20:06:44.713213Z"
    }
   },
   "outputs": [],
   "source": [
    "categorical_feature = np.where(X_train.dtypes != 'float16')[0].tolist()\n",
    "categorical_feature_columns = X_train.select_dtypes(exclude=['float16']).columns\n",
    "#categorical_feature_columns = [feature for feature in train.columns if 'cat' in feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T13:10:18.735222Z",
     "start_time": "2021-08-26T13:10:18.519183Z"
    },
    "execution": {
     "iopub.execute_input": "2021-08-25T20:16:41.618431Z",
     "iopub.status.busy": "2021-08-25T20:16:41.617999Z",
     "iopub.status.idle": "2021-08-25T20:16:41.676033Z",
     "shell.execute_reply": "2021-08-25T20:16:41.674053Z",
     "shell.execute_reply.started": "2021-08-25T20:16:41.618392Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mTrue\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Checking if test categorical unique values are all subsets of their train peers\n",
    "\n",
    "lis = []\n",
    "for i in X_train[categorical_feature_columns].columns:\n",
    "    test_vals = set(test[i].unique())\n",
    "    X_vals = set(X_train[i].unique())\n",
    "    lis.append(test_vals.issubset(X_vals))\n",
    "\n",
    "print(colored(all(lis),'green'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T13:10:19.465895Z",
     "start_time": "2021-08-26T13:10:18.736249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info about train data: \n",
      "Number of rows: \u001b[32m300000\u001b[0m\n",
      "Number of columns: \u001b[32m24\u001b[0m\n",
      "\n",
      "Info about test data: \n",
      "Number of rows: \u001b[32m200000\u001b[0m\n",
      "Number of columns: \u001b[32m24\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#cat_cols = [feature for feature in train.columns if 'cat' in feature]\n",
    "cat_cols = categorical_feature_columns.tolist()\n",
    "\n",
    "def label_encoder(df):\n",
    "    for feature in cat_cols:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "X_train = label_encoder(X_train)\n",
    "X_test = label_encoder(test)\n",
    "\n",
    "print('Info about train data: ')\n",
    "print('Number of rows:',colored(X_train.shape[0],'green'))\n",
    "print('Number of columns:',colored(X_train.shape[1],'green'))\n",
    "\n",
    "print('\\nInfo about test data: ')\n",
    "print('Number of rows:',colored(test.shape[0],'green'))\n",
    "print('Number of columns:',colored(test.shape[1],'green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T13:10:19.473861Z",
     "start_time": "2021-08-26T13:10:19.466896Z"
    },
    "execution": {
     "iopub.execute_input": "2021-08-25T20:17:06.165738Z",
     "iopub.status.busy": "2021-08-25T20:17:06.165381Z",
     "iopub.status.idle": "2021-08-25T20:17:06.178216Z",
     "shell.execute_reply": "2021-08-25T20:17:06.177135Z",
     "shell.execute_reply.started": "2021-08-25T20:17:06.165708Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extreme Fine Tuning LGBM using 7-step training\n",
    "# https://www.kaggle.com/awwalmalhi/extreme-fine-tuning-lgbm-using-7-step-training#Extreme-Fine-Tuning-of-LGBM-using-Incremental-training\n",
    "\n",
    "def objective(trial, X, y, name='xgb'):\n",
    "        \n",
    "    params = {'max_depth':trial.suggest_int('max_depth', 5, 50),\n",
    "              'n_estimators':200000,\n",
    "              #'boosting':trial.suggest_categorical('boosting', ['gbdt', 'dart', 'goss']),\n",
    "              'subsample': trial.suggest_uniform('subsample', 0.2, 1.0),\n",
    "              'colsample_bytree':trial.suggest_uniform('colsample_bytree', 0.2, 1.0),\n",
    "              'learning_rate':trial.suggest_uniform('learning_rate', 0.007, 0.02),\n",
    "              'reg_lambda':trial.suggest_uniform('reg_lambda', 0.01, 50),\n",
    "              'reg_alpha':trial.suggest_uniform('reg_alpha', 0.01, 50),\n",
    "              'min_child_samples':trial.suggest_int('min_child_samples', 5, 100),\n",
    "              'num_leaves':trial.suggest_int('num_leaves', 10, 200),\n",
    "              'n_jobs' : -1,\n",
    "              'metric':'rmse',\n",
    "              'max_bin':trial.suggest_int('max_bin', 300, 1000),\n",
    "              'cat_smooth':trial.suggest_int('cat_smooth', 5, 100),\n",
    "              'cat_l2':trial.suggest_loguniform('cat_l2', 1e-3, 100)}\n",
    "\n",
    "    model = LGBMRegressor(**params)\n",
    "                  \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    \n",
    "\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)],\n",
    "              eval_metric=['rmse'],\n",
    "              early_stopping_rounds=250, \n",
    "              categorical_feature=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "              #callbacks=[optuna.integration.LightGBMPruningCallback(trial, metric='rmse')],\n",
    "              verbose=0)\n",
    "\n",
    "    train_score = np.round(np.sqrt(mean_squared_error(y_train, model.predict(X_train))), 5)\n",
    "    test_score = np.round(np.sqrt(mean_squared_error(y_val, model.predict(X_val))), 5)\n",
    "                  \n",
    "    print(f'TRAIN RMSE : {train_score} || TEST RMSE : {test_score}')\n",
    "                  \n",
    "    return test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T13:10:19.490992Z",
     "start_time": "2021-08-26T13:10:19.475863Z"
    },
    "execution": {
     "iopub.execute_input": "2021-08-25T20:17:13.077646Z",
     "iopub.status.busy": "2021-08-25T20:17:13.077216Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-26 10:10:19,483]\u001b[0m A new study created in memory with name: no-name-08faaa32-4785-4a65-b80f-d3dd877f558c\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "optimize = partial(objective, X=X_train, y=y_train)\n",
    "\n",
    "study_lgbm = optuna.create_study(direction='minimize')\n",
    "#study_lgbm.optimize(optimize, n_trials=50)\n",
    "\n",
    "# i have commented out the trials so as to cut short the notebook execution time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T13:10:19.506991Z",
     "start_time": "2021-08-26T13:10:19.494994Z"
    }
   },
   "outputs": [],
   "source": [
    "#From the above optuna trials the best parameters i could find were the following ones!\n",
    "#study_lgbm.best_params\n",
    "\n",
    "lgbm_params = {\n",
    " 'max_depth': 44,\n",
    " 'subsample': 0.394545907670217,\n",
    " 'colsample_bytree': 0.20198138209747638,\n",
    " 'learning_rate': 0.009310766402801046,\n",
    " 'reg_lambda': 6.237661450596901,\n",
    " 'reg_alpha': 22.879691155166864,\n",
    " 'min_child_samples': 32,\n",
    " 'num_leaves': 17,\n",
    " 'max_bin': 797,\n",
    " 'cat_smooth': 81,\n",
    " 'cat_l2': 3.716241852773303,\n",
    " 'metric': 'rmse', \n",
    " 'n_jobs': -1, \n",
    " 'n_estimators': 20000\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-26T13:10:24.564Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using categorical_feature in Dataset.\n",
      "categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Overriding the parameters from Reference Dataset.\n",
      "categorical_column in param dict is overridden.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Base model is 0.7150945895852655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using categorical_feature in Dataset.\n",
      "categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Overriding the parameters from Reference Dataset.\n",
      "categorical_column in param dict is overridden.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Incremental trial 1 model is 0.7150912380025591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using categorical_feature in Dataset.\n",
      "categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Overriding the parameters from Reference Dataset.\n",
      "categorical_column in param dict is overridden.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Incremental trial 2 model is 0.7150585221872836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using categorical_feature in Dataset.\n",
      "categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Overriding the parameters from Reference Dataset.\n",
      "categorical_column in param dict is overridden.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Incremental trial 3 model is 0.7150295932633853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using categorical_feature in Dataset.\n",
      "categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Overriding the parameters from Reference Dataset.\n",
      "categorical_column in param dict is overridden.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Incremental trial 4 model is 0.7150222531174983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using categorical_feature in Dataset.\n",
      "categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Overriding the parameters from Reference Dataset.\n",
      "categorical_column in param dict is overridden.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Incremental trial 5 model is 0.7150090516998127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using categorical_feature in Dataset.\n",
      "categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Overriding the parameters from Reference Dataset.\n",
      "categorical_column in param dict is overridden.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Incremental trial 6 model is 0.7150030474578102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using categorical_feature in Dataset.\n",
      "categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Overriding the parameters from Reference Dataset.\n",
      "categorical_column in param dict is overridden.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Incremental trial 7 model is 0.7149994029251712\n",
      "\n",
      "\n",
      "Improvement of : 9.51866600943374e-05\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "split = KFold(n_splits=10, shuffle=True)\n",
    "#split = KFold(n_splits=5, random_state=2, shuffle=True)\n",
    "\n",
    "preds_list_base = []\n",
    "preds_list_final_iteration = []\n",
    "preds_list_all = []\n",
    "\n",
    "for train_idx, val_idx in split.split(X_train):\n",
    "            X_tr = X_train.iloc[train_idx]\n",
    "            X_val = X_train.iloc[val_idx]\n",
    "            y_tr = y_train.iloc[train_idx]\n",
    "            y_val = y_train.iloc[val_idx]\n",
    "            \n",
    "            Model = LGBMRegressor(**lgbm_params).fit(X_tr, y_tr, eval_set=[(X_val, y_val)],\n",
    "                          eval_metric=['rmse'],\n",
    "                          early_stopping_rounds=250, \n",
    "                          categorical_feature=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                          #callbacks=[optuna.integration.LightGBMPruningCallback(trial, metric='rmse')],\n",
    "                          verbose=0)\n",
    "            \n",
    "            preds_list_base.append(Model.predict(X_test))\n",
    "            preds_list_all.append(Model.predict(X_test))\n",
    "            print(f'RMSE for Base model is {np.sqrt(mean_squared_error(y_val, Model.predict(X_val)))}')\n",
    "            first_rmse = np.sqrt(mean_squared_error(y_val, Model.predict(X_val)))\n",
    "            params = lgbm_params.copy()\n",
    "            \n",
    "            for i in range(1, 8):\n",
    "                if i >2:    \n",
    "                    \n",
    "                    # reducing regularizing params if \n",
    "                    \n",
    "                    params['reg_lambda'] *= 0.9\n",
    "                    params['reg_alpha'] *= 0.9\n",
    "                    params['num_leaves'] += 40\n",
    "                    \n",
    "                params['learning_rate'] = 0.003\n",
    "                Model = LGBMRegressor(**params).fit(X_tr, y_tr, eval_set=[(X_val, y_val)],\n",
    "                          eval_metric=['rmse'],\n",
    "                          early_stopping_rounds=200, \n",
    "                          categorical_feature=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                          #callbacks=[optuna.integration.LightGBMPruningCallback(trial, metric='rmse')],\n",
    "                          verbose=0,\n",
    "                          init_model=Model)\n",
    "                \n",
    "                preds_list_all.append(Model.predict(X_test))\n",
    "                print(f'RMSE for Incremental trial {i} model is {np.sqrt(mean_squared_error(y_val, Model.predict(X_val)))}')\n",
    "            last_rmse = np.sqrt(mean_squared_error(y_val, Model.predict(X_val)))\n",
    "            print('',end='\\n\\n')\n",
    "            print(f'Improvement of : {first_rmse - last_rmse}')\n",
    "            print('-' * 100)\n",
    "            preds_list_final_iteration.append(Model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Submit to the competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T05:15:14.960087Z",
     "start_time": "2021-08-26T05:15:14.946088Z"
    }
   },
   "outputs": [],
   "source": [
    "y_preds_base = np.array(preds_list_base).mean(axis=0)\n",
    "y_preds_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T05:15:15.023573Z",
     "start_time": "2021-08-26T05:15:14.962088Z"
    }
   },
   "outputs": [],
   "source": [
    "y_preds_all = np.array(preds_list_all).mean(axis=0)\n",
    "y_preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T05:15:15.055089Z",
     "start_time": "2021-08-26T05:15:15.027281Z"
    }
   },
   "outputs": [],
   "source": [
    "y_preds_final_iteration = np.array(preds_list_final_iteration).mean(axis=0)\n",
    "y_preds_final_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T05:15:15.497720Z",
     "start_time": "2021-08-26T05:15:15.056088Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use the model to generate predictions\n",
    "#predictions = model.predict(test)\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "output = pd.DataFrame({'Id': test.index,\n",
    "                       'target': y_preds_final_iteration})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
